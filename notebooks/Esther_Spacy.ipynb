{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Esther's Text Processing Notebook Using Spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will focus on using Spacy for natural language processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing and Installing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\esthe\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (24.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\esthe\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (69.5.1)\n",
      "Requirement already satisfied: wheel in c:\\users\\esthe\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (0.43.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Invalid requirement: \"'spacy[cuda11x,transformers,lookups]'\"\n",
      "c:\\Users\\esthe\\AppData\\Local\\Programs\\Python\\Python311\\python.exe: No module named spacy\n"
     ]
    }
   ],
   "source": [
    "# Run in terminal for importing english pipeline, use of GPU, to train models\n",
    "'''\n",
    "!pip install -U pip setuptools wheel\n",
    "!pip install -U 'spacy[cuda11x,transformers,lookups]'\n",
    "!python -m spacy download en_core_web_trf\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "from multiprocessing import Process\n",
    "import spacy\n",
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\esthe\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\transformers\\utils\\generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "C:\\Users\\esthe\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\transformers\\utils\\generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "# load the english model\n",
    "import spacy\n",
    "spacy.prefer_gpu()\n",
    "nlp = spacy.load('en_core_web_trf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieving the Dataset from Dropbox + Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe loaded from Dropbox:\n",
      "   Unnamed: 0                                            Content  \\\n",
      "0           0  new york reuters us environmental group sierra...   \n",
      "1           1  washington reuters us air force asked industry...   \n",
      "2           2  saturday paul ryan posted photo instagram phot...   \n",
      "3           3  america keeps waiting word hillary indicted ob...   \n",
      "4           4                   religion peace ht weasel zippers   \n",
      "\n",
      "          Title  Type  \n",
      "0  politicsNews  true  \n",
      "1  politicsNews  true  \n",
      "2          News  fake  \n",
      "3      politics  fake  \n",
      "4     left-news  fake  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "import dropbox\n",
    "import pandas as pd\n",
    "import io\n",
    "import os \n",
    "#from config import dropbox_access_token\n",
    "\n",
    "dropbox_access_token = 'sl.B0OyrqIVh5-MnCgbx9Vp9ZBe3UVv496hSidwMqXTtkIW-733ex9vaUN8aIxTMWKXrY4DD_cIJVx9griph0OVJK3TCnKsqi64viEj09FrnBScUNMw464e7PLkadxwfrcdHfsIbksqfS9r'\n",
    "\n",
    "# Initialize Dropbox client\n",
    "dbx = dropbox.Dropbox(dropbox_access_token)\n",
    "\n",
    "# Dropbox file path\n",
    "dropbox_file_path = '/fake_real_ML_project_dataset.csv'\n",
    "\n",
    "# Download the file\n",
    "metadata, response = dbx.files_download(dropbox_file_path)\n",
    "\n",
    "# Read the CSV file from the response content using io.BytesIO\n",
    "df = pd.read_csv(io.BytesIO(response.content))\n",
    "\n",
    "# Show the results\n",
    "print(\"Dataframe loaded from Dropbox:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run C:\\Users\\esthe\\DSEI2100_Project\\machine-learning-dse-i210-final-project-fake-news\\data\\external\\ML_dataset_dropbox.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove extra column\n",
    "df = df.drop('Unnamed: 0', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "      <th>Title</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>new york reuters us environmental group sierra...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>washington reuters us air force asked industry...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>saturday paul ryan posted photo instagram phot...</td>\n",
       "      <td>News</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>america keeps waiting word hillary indicted ob...</td>\n",
       "      <td>politics</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>religion peace ht weasel zippers</td>\n",
       "      <td>left-news</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Content         Title  Type\n",
       "0  new york reuters us environmental group sierra...  politicsNews  true\n",
       "1  washington reuters us air force asked industry...  politicsNews  true\n",
       "2  saturday paul ryan posted photo instagram phot...          News  fake\n",
       "3  america keeps waiting word hillary indicted ob...      politics  fake\n",
       "4                   religion peace ht weasel zippers     left-news  fake"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44266, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section of the notebook will focus on using Spacy to process and extract information relevant to our goal of creating a fake news classification model.\n",
    "\n",
    "We will use GPU to do these tasks and time them in order to compare them to our NLTK base."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spacy Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_df(df):\n",
    "    df['Tokens'] = df['Content'].apply(lambda x: [token.text for token in nlp(x)])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_process = Process(target=tokenize_df, args=(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#token_process.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_process.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_process.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['Tokens'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def tokenize_df(df):\n",
    "    df['Tokens'] = df['Content'].apply(lambda x: [token.text for token in nlp(x)])\n",
    "    return df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Define the process\n",
    "    token_process = Process(target=tokenize_df, args=(df.copy(),))\n",
    "\n",
    "    # Start the process\n",
    "    token_process.start()\n",
    "\n",
    "    # Wait for the process to finish\n",
    "    token_process.join()\n",
    "\n",
    "    # Print the DataFrame after the process completes\n",
    "    print(\"Printing DataFrame:\")\n",
    "    print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spacy Lemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemmatize the text (takes much longer to run than nltk)\n",
    "def lemmatize_df(df):\n",
    "    df['lem_toks_spcy'] = df['Tokens'].apply(lambda tokens: [token.lemma_ for token in tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatize_process = Process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatize_process.start()\n",
    "lemmatize_process.join()\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spacy POS Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_df(df):\n",
    "    df['pos_tag'] = df['Tokens'].apply(lambda tokens: [token.pos_ for token in tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spacy Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = df['Tokens'].loc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "displacy.render(doc, style='dep')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spacy Entity Recognizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "spaCy's statistical entity recognition system assigns labels to contigouos spans of tokens. It works to identify a variety of named numeric entities including companies, locations, organizations, and products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spacy Text Categorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
