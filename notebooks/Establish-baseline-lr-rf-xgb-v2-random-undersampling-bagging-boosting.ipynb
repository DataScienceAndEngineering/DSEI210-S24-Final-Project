{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","authorship_tag":"ABX9TyNHJISkEQ999iFDMkEZ1SeF"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kiT4aG5rD_5_","executionInfo":{"status":"ok","timestamp":1715106283572,"user_tz":240,"elapsed":24682,"user":{"displayName":"Adnan Arnaout","userId":"12696578744360296452"}},"outputId":"6e12828a-21dc-40c7-e129-172c5c4efef9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.2.2)\n"]}],"source":["pip install requests"]},{"cell_type":"code","source":["import requests\n","\n","# URL of the notebook raw file\n","url = \"https://raw.githubusercontent.com/adnanarnaout/machine-learning-dse-i210-final-project-nyc-car-accident-severity/main/notebooks/Establish-baseline-logistic-regression-model-AA.ipynb\"\n","\n","# Make a GET request to fetch the raw content of the notebook\n","r = requests.get(url)\n","if r.status_code == 200:\n","    # Saving the notebook\n","    with open('local_notebook.ipynb', 'wb') as f:\n","        f.write(r.content)\n","    print(\"Notebook downloaded successfully.\")\n","else:\n","    print(\"Failed to download the notebook. Status code:\", r.status_code)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_irEJ3S7EUQw","executionInfo":{"status":"ok","timestamp":1715106284351,"user_tz":240,"elapsed":783,"user":{"displayName":"Adnan Arnaout","userId":"12696578744360296452"}},"outputId":"23533fae-05be-47d2-e511-cbab44ec212d"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Notebook downloaded successfully.\n"]}]},{"cell_type":"code","source":["%run './local_notebook.ipynb'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Uqudh2JbEYEc","executionInfo":{"status":"ok","timestamp":1715106386908,"user_tz":240,"elapsed":102559,"user":{"displayName":"Adnan Arnaout","userId":"12696578744360296452"}},"outputId":"2b41c7df-384f-4e7d-c13c-443e164188e3"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 1057417 entries, 0 to 1057416\n","Data columns (total 15 columns):\n"," #   Column                         Non-Null Count    Dtype  \n","---  ------                         --------------    -----  \n"," 0   CRASH DATE                     1057417 non-null  object \n"," 1   CRASH TIME                     1057417 non-null  object \n"," 2   LATITUDE                       1057417 non-null  float64\n"," 3   LONGITUDE                      1057417 non-null  float64\n"," 4   CONTRIBUTING FACTOR VEHICLE 1  1057417 non-null  object \n"," 5   CONTRIBUTING FACTOR VEHICLE 2  1057417 non-null  object \n"," 6   CONTRIBUTING FACTOR VEHICLE 3  1057417 non-null  object \n"," 7   CONTRIBUTING FACTOR VEHICLE 4  1057417 non-null  object \n"," 8   CONTRIBUTING FACTOR VEHICLE 5  1057417 non-null  object \n"," 9   VEHICLE TYPE CODE 1            1057417 non-null  object \n"," 10  VEHICLE TYPE CODE 2            1057417 non-null  object \n"," 11  VEHICLE TYPE CODE 3            1057417 non-null  object \n"," 12  VEHICLE TYPE CODE 4            1057417 non-null  object \n"," 13  VEHICLE TYPE CODE 5            1057417 non-null  object \n"," 14  CLASS TYPE                     1057417 non-null  object \n","dtypes: float64(2), object(13)\n","memory usage: 121.0+ MB\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-3-9402aef63446>:9: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n","  mvc_processed['temp_datetime'] = pd.to_datetime(mvc_processed['CRASH TIME'].astype(str))\n","/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["Accuracy: 0.8146762875678538\n","Confusion Matrix:\n"," [[159760   5079      0      0]\n"," [ 33727  12531      0      0]\n"," [   179     27      0      0]\n"," [   101     80      0      0]]\n","Classification Report:\n","               precision    recall  f1-score   support\n","\n","           0       0.82      0.97      0.89    164839\n","           1       0.71      0.27      0.39     46258\n","           2       0.00      0.00      0.00       206\n","           3       0.00      0.00      0.00       181\n","\n","    accuracy                           0.81    211484\n","   macro avg       0.38      0.31      0.32    211484\n","weighted avg       0.80      0.81      0.78    211484\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}]},{"cell_type":"code","source":["from sklearn.ensemble import RandomForestClassifier\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","\n","# Initialize the RandomForestClassifier\n","# Setting class_weight='balanced' to handle imbalanced dataset if needed\n","rf = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced',\n","                            n_jobs=-1)\n","\n","# Fit the RandomForest model on the training data\n","rf.fit(X_train_scaled, y_train)\n","\n","# Predict the labels for the test set\n","predictions = rf.predict(X_test_scaled)\n","\n","# Calculate the accuracy of the predictions\n","accuracy = accuracy_score(y_test, predictions)\n","\n","# Output the accuracy\n","print(f\"Accuracy: {accuracy:.2%}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rnTsHjs7HC-B","executionInfo":{"status":"ok","timestamp":1714956703588,"user_tz":240,"elapsed":82202,"user":{"displayName":"Adnan Arnaout","userId":"12696578744360296452"}},"outputId":"6814e3b6-3e13-4966-9653-4064f9a92ad9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 82.44%\n"]}]},{"cell_type":"markdown","source":[],"metadata":{"id":"hK7P3BtnY0Bh"}},{"cell_type":"code","source":["print(classification_report(y_test, predictions))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PeA6ia8gUfA9","executionInfo":{"status":"ok","timestamp":1714956749977,"user_tz":240,"elapsed":469,"user":{"displayName":"Adnan Arnaout","userId":"12696578744360296452"}},"outputId":"b7bc52ff-21e6-41b5-cdbd-4560c4526492"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.83      0.97      0.90    164839\n","           1       0.74      0.31      0.44     46258\n","           2       1.00      0.00      0.01       206\n","           3       0.00      0.00      0.00       181\n","\n","    accuracy                           0.82    211484\n","   macro avg       0.64      0.32      0.34    211484\n","weighted avg       0.81      0.82      0.80    211484\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}]},{"cell_type":"code","source":["import xgboost as xgb\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","\n","# Initialize the XGBoost classifier\n","xgb_clf = xgb.XGBClassifier(objective='binary:logistic', n_estimators=100, n_jobs=-1,\n","                            seed=42, use_label_encoder=False)\n","\n","# Fit the XGBoost model on the training data\n","xgb_clf.fit(X_train_scaled, y_train, eval_metric='logloss')\n","\n","# Predict the labels for the test set\n","predictions_xgb = xgb_clf.predict(X_test_scaled)\n","\n","# Calculate the accuracy of the predictions\n","accuracy = accuracy_score(y_test, predictions_xgb)\n","\n","# Output the accuracy\n","print(f\"Accuracy: {accuracy:.2%}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FFCi90QaYyBS","executionInfo":{"status":"ok","timestamp":1714956997357,"user_tz":240,"elapsed":27953,"user":{"displayName":"Adnan Arnaout","userId":"12696578744360296452"}},"outputId":"565783c6-011a-406f-dffa-a4013f8e3323"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Accuracy: 82.60%\n"]}]},{"cell_type":"code","source":["print(classification_report(y_test, predictions_xgb))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cG3a0s-3ZqUl","executionInfo":{"status":"ok","timestamp":1714957020759,"user_tz":240,"elapsed":427,"user":{"displayName":"Adnan Arnaout","userId":"12696578744360296452"}},"outputId":"46a2769d-a9ce-4a96-f878-6886eb811843"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.84      0.96      0.90    164839\n","           1       0.73      0.34      0.46     46258\n","           2       0.00      0.00      0.00       206\n","           3       0.00      0.00      0.00       181\n","\n","    accuracy                           0.83    211484\n","   macro avg       0.39      0.33      0.34    211484\n","weighted avg       0.81      0.83      0.80    211484\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}]},{"cell_type":"code","source":["# Addressing class imbalance\n","\n","from imblearn.over_sampling import SMOTE\n","from sklearn.model_selection import train_test_split\n","import numpy as np\n","\n","# Initialize SMOTE\n","smote = SMOTE(random_state=42)\n","\n","# Fit SMOTE on the training data only\n","X_train_smote, y_train_smote = smote.fit_resample(X_train_scaled, y_train)\n","\n","# Check the balance\n","print(f\"Original training dataset shape {np.bincount(y_train)}\")\n","print(f\"Resampled training dataset shape {np.bincount(y_train_smote)}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZJUMo3ERZ2wV","executionInfo":{"status":"ok","timestamp":1715106950655,"user_tz":240,"elapsed":381082,"user":{"displayName":"Adnan Arnaout","userId":"12696578744360296452"}},"outputId":"ca908eac-0045-40ee-ff2d-aedc8bd71ab1"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Original training dataset shape [659354 185031    824    724]\n","Resampled training dataset shape [659354 659354 659354 659354]\n"]}]},{"cell_type":"code","source":["# Run logisitic regression model on resampled training dataset\n","\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import classification_report\n","\n","# Initialize the Logistic Regression model\n","log_reg = LogisticRegression(max_iter=1000, n_jobs=-1)\n","\n","# Fit the model on the training data\n","log_reg.fit(X_train_smote, y_train_smote)\n","\n","# Predict the labels for both the training and test sets\n","train_predictions_lr = log_reg.predict(X_train_smote)\n","test_predictions_lr = log_reg.predict(X_test_scaled)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":382},"id":"AzJDs_jzmKYP","executionInfo":{"status":"error","timestamp":1714961263231,"user_tz":240,"elapsed":571600,"user":{"displayName":"Adnan Arnaout","userId":"12696578744360296452"}},"outputId":"a2a6979d-e10e-458a-d64d-daba0cf6b38e"},"execution_count":null,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"Found input variables with inconsistent numbers of samples: [845933, 2637416]","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-4261b17f8a04>\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Generate classification reports\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mtrain_report\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_predictions_lr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mtest_report\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_predictions_lr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[1;32m   2308\u001b[0m     \"\"\"\n\u001b[1;32m   2309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2310\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2312\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \"\"\"\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y_true\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y_pred\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    395\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 397\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    398\u001b[0m             \u001b[0;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m             \u001b[0;34m%\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [845933, 2637416]"]}]},{"cell_type":"code","source":["# Generate classification reports\n","\n","train_report = classification_report(y_train_smote, train_predictions_lr)\n","test_report = classification_report(y_test, test_predictions_lr)\n","\n","# Print the classification reports\n","print(\"Training Classification Report:\\n\", train_report)\n","print(\"Testing Classification Report:\\n\", test_report)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0PEmE8yznhGm","executionInfo":{"status":"ok","timestamp":1714961467956,"user_tz":240,"elapsed":5307,"user":{"displayName":"Adnan Arnaout","userId":"12696578744360296452"}},"outputId":"c897d7ba-31b8-4764-bf53-6702294cd434"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training Classification Report:\n","               precision    recall  f1-score   support\n","\n","           0       0.51      0.55      0.53    659354\n","           1       0.49      0.20      0.28    659354\n","           2       0.55      0.70      0.62    659354\n","           3       0.64      0.80      0.71    659354\n","\n","    accuracy                           0.56   2637416\n","   macro avg       0.55      0.56      0.53   2637416\n","weighted avg       0.55      0.56      0.53   2637416\n","\n","Testing Classification Report:\n","               precision    recall  f1-score   support\n","\n","           0       0.89      0.54      0.67    164839\n","           1       0.38      0.20      0.26     46258\n","           2       0.00      0.54      0.00       206\n","           3       0.00      0.80      0.01       181\n","\n","    accuracy                           0.47    211484\n","   macro avg       0.32      0.52      0.24    211484\n","weighted avg       0.77      0.47      0.58    211484\n","\n"]}]},{"cell_type":"code","source":["rf = RandomForestClassifier(n_estimators=100, random_state=42,\n","                            n_jobs=-1)\n","\n","# Fit the RandomForest model on the training data\n","rf.fit(X_train_smote, y_train_smote)\n","\n","# Predict the labels for the test set\n","predictions_rf_smote = rf.predict(X_test_scaled)\n","\n","# Calculate the accuracy of the predictions\n","accuracy = accuracy_score(y_test, predictions_rf_smote)\n","\n","# Output the accuracy\n","print(f\"Accuracy: {accuracy:.2%}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yU-x7QcoqzTX","executionInfo":{"status":"ok","timestamp":1714963169622,"user_tz":240,"elapsed":343792,"user":{"displayName":"Adnan Arnaout","userId":"12696578744360296452"}},"outputId":"1ab1471e-6e85-4d4e-a2cf-f3a02b14976a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 81.14%\n"]}]},{"cell_type":"code","source":["print(classification_report(y_test, predictions_rf_smote))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CBzIGERPwAHE","executionInfo":{"status":"ok","timestamp":1714963585627,"user_tz":240,"elapsed":446,"user":{"displayName":"Adnan Arnaout","userId":"12696578744360296452"}},"outputId":"cf051b5b-6379-433d-a069-b09660f627e4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.85      0.92      0.88    164839\n","           1       0.60      0.43      0.50     46258\n","           2       0.05      0.00      0.01       206\n","           3       0.00      0.00      0.00       181\n","\n","    accuracy                           0.81    211484\n","   macro avg       0.38      0.34      0.35    211484\n","weighted avg       0.79      0.81      0.80    211484\n","\n"]}]},{"cell_type":"code","source":["# Undersampling the majority class\n","\n","from imblearn.under_sampling import RandomUnderSampler\n","\n","# Initialize the RandomUnderSampler\n","rus = RandomUnderSampler(random_state=42)\n","\n","# Resample the training set\n","X_train_rus, y_train_rus = rus.fit_resample(X_train_scaled, y_train)\n","\n","# Now you can proceed with training your model on this new downsampled dataset\n"],"metadata":{"id":"2GfDdA9JytA5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Initialize the Logistic Regression model\n","log_reg_rus = LogisticRegression(max_iter=1000)\n","\n","# Fit the model on the downsampled training data from RandomUnderSampler\n","log_reg_rus.fit(X_train_rus, y_train_rus)\n","\n","# Predict the labels for the test set\n","train_predictions_log_reg_rus = log_reg_rus.predict(X_train_rus)\n","test_predictions_log_reg_rus = log_reg_rus.predict(X_test_scaled)\n","\n","# Generate classification reports for both training and test data\n","train_report_rus = classification_report(y_train_rus, train_predictions_log_reg_rus)\n","test_report_rus = classification_report(y_test, test_predictions_log_reg_rus)\n","\n","# Print the classification reports\n","print(\"Training Classification Report for RandomUnderSampler Data:\\n\", train_report_rus)\n","print(\"Testing Classification Report for RandomUnderSampler Data:\\n\", test_report_rus)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P_glXdr85KXa","executionInfo":{"status":"ok","timestamp":1715032660768,"user_tz":240,"elapsed":1350,"user":{"displayName":"Adnan Arnaout","userId":"12696578744360296452"}},"outputId":"21e589de-72a5-48b5-b504-9ff8ebf832d8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training Classification Report for RandomUnderSampler Data:\n","               precision    recall  f1-score   support\n","\n","           0       0.51      0.57      0.53       724\n","           1       0.49      0.20      0.28       724\n","           2       0.54      0.68      0.60       724\n","           3       0.64      0.79      0.71       724\n","\n","    accuracy                           0.56      2896\n","   macro avg       0.55      0.56      0.53      2896\n","weighted avg       0.55      0.56      0.53      2896\n","\n","Testing Classification Report for RandomUnderSampler Data:\n","               precision    recall  f1-score   support\n","\n","           0       0.88      0.54      0.67    164839\n","           1       0.37      0.18      0.24     46258\n","           2       0.00      0.54      0.00       206\n","           3       0.00      0.80      0.01       181\n","\n","    accuracy                           0.46    211484\n","   macro avg       0.31      0.51      0.23    211484\n","weighted avg       0.77      0.46      0.57    211484\n","\n"]}]},{"cell_type":"code","source":["import xgboost as xgb\n","from sklearn.metrics import classification_report\n","from imblearn.under_sampling import RandomUnderSampler\n","\n","# Initialize the XGBoost classifier with n_jobs=-1 to use all CPU cores\n","xgb_clf = xgb.XGBClassifier(\n","    n_estimators=100,\n","    learning_rate=0.1,\n","    max_depth=3,\n","    objective='binary:logistic',\n","    use_label_encoder=False,\n","    eval_metric='logloss',\n","    n_jobs=-1,\n","    seed=42\n",")\n","\n","# Fit the XGBoost model on the balanced training data\n","xgb_clf.fit(X_train_rus, y_train_rus)\n","\n","# Predict the labels for both the training and test sets\n","train_predictions_xgb = xgb_clf.predict(X_train_rus)\n","test_predictions_xgb = xgb_clf.predict(X_test_scaled)\n","\n","# Generate classification reports for both training and test data\n","train_report_xgb = classification_report(y_train_rus, train_predictions_xgb)\n","test_report_xgb = classification_report(y_test, test_predictions_xgb)\n","\n","# Print the classification reports\n","print(\"Training Classification Report for XGBoost with RandomUnderSampler Data:\\n\", train_report_xgb)\n","print(\"Testing Classification Report for XGBoost with RandomUnderSampler Data:\\n\", test_report_xgb)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"27Tt-CJw69IC","executionInfo":{"status":"ok","timestamp":1715034056172,"user_tz":240,"elapsed":3542,"user":{"displayName":"Adnan Arnaout","userId":"12696578744360296452"}},"outputId":"79127419-32a5-4687-a4b6-bfb84e0ab8c7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training Classification Report for XGBoost with RandomUnderSampler Data:\n","               precision    recall  f1-score   support\n","\n","           0       0.58      0.70      0.63       724\n","           1       0.68      0.27      0.39       724\n","           2       0.61      0.74      0.67       724\n","           3       0.68      0.80      0.73       724\n","\n","    accuracy                           0.63      2896\n","   macro avg       0.64      0.63      0.60      2896\n","weighted avg       0.64      0.63      0.60      2896\n","\n","Testing Classification Report for XGBoost with RandomUnderSampler Data:\n","               precision    recall  f1-score   support\n","\n","           0       0.88      0.62      0.73    164839\n","           1       0.40      0.17      0.24     46258\n","           2       0.00      0.61      0.01       206\n","           3       0.00      0.81      0.01       181\n","\n","    accuracy                           0.52    211484\n","   macro avg       0.32      0.55      0.25    211484\n","weighted avg       0.78      0.52      0.62    211484\n","\n"]}]},{"cell_type":"code","source":["# Bagging with Decision Trees\n","\n","from sklearn.ensemble import BaggingClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.metrics import classification_report\n","\n","# Initialize the base classifier\n","tree = DecisionTreeClassifier()\n","\n","# Initialize the Bagging classifier with Decision Trees\n","bagging_clf = BaggingClassifier(\n","    base_estimator=tree,\n","    n_estimators=100,  # Number of trees in the forest\n","    max_samples=0.8,   # The proportion of the dataset to include in each bootstrap sample\n","    max_features=0.8,  # The proportion of features to draw from X to train each base estimator\n","    random_state=42,\n","    n_jobs=-1           # Use all cores\n",")\n","\n","# Fit the model on the training data\n","bagging_clf.fit(X_train_scaled, y_train)\n","\n","# Predict the labels for the test set\n","predictions = bagging_clf.predict(X_test_scaled)\n","\n","# Generate a classification report\n","report = classification_report(y_test, predictions)\n","\n","# Print the classification report\n","print(\"Classification Report:\\n\", report)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZkoZXxTM6ZT7","executionInfo":{"status":"ok","timestamp":1715034442554,"user_tz":240,"elapsed":226468,"user":{"displayName":"Adnan Arnaout","userId":"12696578744360296452"}},"outputId":"2edb2837-8be3-4409-d7f3-44c05f3fe8f7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Classification Report:\n","               precision    recall  f1-score   support\n","\n","           0       0.83      0.97      0.90    164839\n","           1       0.73      0.32      0.45     46258\n","           2       1.00      0.00      0.01       206\n","           3       0.00      0.00      0.00       181\n","\n","    accuracy                           0.82    211484\n","   macro avg       0.64      0.32      0.34    211484\n","weighted avg       0.81      0.82      0.80    211484\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}]},{"cell_type":"code","source":["# Bagging with RandomForest\n","\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import classification_report\n","\n","# Initialize the Random Forest classifier\n","random_forest = RandomForestClassifier(\n","    n_estimators=100,\n","    max_depth=None,   # Let the trees grow large\n","    random_state=42,\n","    n_jobs=-1,        # Use all cores\n","    class_weight='balanced'  # Automatically adjust weights inversely proportional to class frequencies\n",")\n","\n","# Fit the model on the training data\n","random_forest.fit(X_train_scaled, y_train)\n","\n","# Predict the labels for the test set\n","rf_predictions = random_forest.predict(X_test_scaled)\n","\n","# Generate a classification report\n","rf_report = classification_report(y_test, rf_predictions)\n","\n","# Print the classification report\n","print(\"Random Forest Classification Report:\\n\", rf_report)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MnVRPBLUAVYa","executionInfo":{"status":"ok","timestamp":1715034586613,"user_tz":240,"elapsed":60004,"user":{"displayName":"Adnan Arnaout","userId":"12696578744360296452"}},"outputId":"b4dc8c91-f40a-4e38-a5a2-f285c6e308fd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Random Forest Classification Report:\n","               precision    recall  f1-score   support\n","\n","           0       0.83      0.97      0.90    164839\n","           1       0.74      0.31      0.44     46258\n","           2       1.00      0.00      0.01       206\n","           3       0.00      0.00      0.00       181\n","\n","    accuracy                           0.82    211484\n","   macro avg       0.64      0.32      0.34    211484\n","weighted avg       0.81      0.82      0.80    211484\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}]},{"cell_type":"code","source":["from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report\n","from sklearn.preprocessing import StandardScaler\n","\n","# Initialize the KNN classifier\n","knn = KNeighborsClassifier(n_neighbors=6, n_jobs=-1)\n","\n","# Fit the model on the training data\n","knn.fit(X_train_scaled, y_train)\n","\n","# Predict the labels for both the training and test sets\n","train_predictions = knn.predict(X_train_scaled)\n","test_predictions = knn.predict(X_test_scaled)\n","\n","# Generate classification reports for both training and test data\n","train_report = classification_report(y_train, train_predictions)\n","test_report = classification_report(y_test, test_predictions)\n","\n","# Print the classification reports\n","print(\"Training Classification Report:\\n\", train_report)\n","print(\"Testing Classification Report:\\n\", test_report)\n"],"metadata":{"id":"2Zhbn7P6BhMU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":144},"id":"WVaF4u4kEhBf","executionInfo":{"status":"error","timestamp":1715038260131,"user_tz":240,"elapsed":427,"user":{"displayName":"Adnan Arnaout","userId":"12696578744360296452"}},"outputId":"a6989036-e77c-4a7b-a04c-184d0cfc4e86"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'X_train' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-931765772341>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"]}]},{"cell_type":"code","source":[],"metadata":{"id":"WKrZEwZtPwO2"},"execution_count":null,"outputs":[]}]}