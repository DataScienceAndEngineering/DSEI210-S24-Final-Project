{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "156f885a-84a1-4a49-8271-3fcbb5658b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ed0e1b6-46ab-4c38-9d33-0374084a9e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the folder\n",
    "folder_path = Path(\"C:/Users/crazy/OneDrive - The City College of New York/DSE I2100 - Applied Machine Learning and Data Mining/Project\")\n",
    "csv_file = folder_path.glob(\"Processed_Data_v2.csv\").__next__()\n",
    "\n",
    "# Load CSV file into DataFrame\n",
    "data = pd.read_csv(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb86770f-44b6-416d-98cd-203126414f82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1057417 entries, 0 to 1057416\n",
      "Data columns (total 15 columns):\n",
      " #   Column                         Non-Null Count    Dtype  \n",
      "---  ------                         --------------    -----  \n",
      " 0   CRASH DATE                     1057417 non-null  object \n",
      " 1   CRASH TIME                     1057417 non-null  object \n",
      " 2   LATITUDE                       1057417 non-null  float64\n",
      " 3   LONGITUDE                      1057417 non-null  float64\n",
      " 4   CONTRIBUTING FACTOR VEHICLE 1  1057417 non-null  object \n",
      " 5   CONTRIBUTING FACTOR VEHICLE 2  1057417 non-null  object \n",
      " 6   CONTRIBUTING FACTOR VEHICLE 3  1057417 non-null  object \n",
      " 7   CONTRIBUTING FACTOR VEHICLE 4  1057417 non-null  object \n",
      " 8   CONTRIBUTING FACTOR VEHICLE 5  1057417 non-null  object \n",
      " 9   VEHICLE TYPE CODE 1            1057417 non-null  object \n",
      " 10  VEHICLE TYPE CODE 2            1057417 non-null  object \n",
      " 11  VEHICLE TYPE CODE 3            1057417 non-null  object \n",
      " 12  VEHICLE TYPE CODE 4            1057417 non-null  object \n",
      " 13  VEHICLE TYPE CODE 5            1057417 non-null  object \n",
      " 14  CLASS TYPE                     1057417 non-null  object \n",
      "dtypes: float64(2), object(13)\n",
      "memory usage: 121.0+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info(show_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97d3c71f-6296-4720-88a2-a22db81abbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select categorical columns for encoding\n",
    "cat_cols = ['CONTRIBUTING FACTOR VEHICLE 1', 'CONTRIBUTING FACTOR VEHICLE 2',\n",
    "            'CONTRIBUTING FACTOR VEHICLE 3', 'CONTRIBUTING FACTOR VEHICLE 4',\n",
    "            'CONTRIBUTING FACTOR VEHICLE 5', 'VEHICLE TYPE CODE 1', 'VEHICLE TYPE CODE 2',\n",
    "            'VEHICLE TYPE CODE 3', 'VEHICLE TYPE CODE 4', 'VEHICLE TYPE CODE 5']\n",
    "\n",
    "# Initialize OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "\n",
    "# Encode categorical variables\n",
    "encoded_cols = pd.DataFrame(encoder.fit_transform(data[cat_cols]))\n",
    "encoded_cols.columns = encoder.get_feature_names_out(cat_cols)\n",
    "\n",
    "# Replace categorical columns with encoded ones\n",
    "data = pd.concat([data.drop(columns=cat_cols), encoded_cols], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfbba25b-855b-49b4-bf7f-bd18c7090167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features from 'CRASH DATE' and 'CRASH TIME'\n",
    "data['CRASH DATE'] = pd.to_datetime(data['CRASH DATE'])\n",
    "data['CRASH TIME'] = pd.to_datetime(data['CRASH TIME'])\n",
    "\n",
    "data['year'] = data['CRASH DATE'].dt.year\n",
    "data['month'] = data['CRASH DATE'].dt.month\n",
    "data['day'] = data['CRASH DATE'].dt.day\n",
    "data['day_of_week'] = data['CRASH DATE'].dt.dayofweek\n",
    "\n",
    "data['hour'] = data['CRASH TIME'].dt.hour\n",
    "data['minute'] = data['CRASH TIME'].dt.minute\n",
    "data['second'] = data['CRASH TIME'].dt.second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa9033b8-2ded-472f-8fb6-8392d30e5ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into features (X) and target variable (y)\n",
    "X = data.drop(columns=['CLASS TYPE','CRASH DATE', 'CRASH TIME'])\n",
    "y = data['CLASS TYPE']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58432bce-a8e1-4837-8b64-5c74dd46036f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1057417 entries, 0 to 1057416\n",
      "Columns: 108 entries, LATITUDE to second\n",
      "dtypes: float64(101), int64(7)\n",
      "memory usage: 871.3 MB\n"
     ]
    }
   ],
   "source": [
    "X.info(show_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e72a31d-5fb9-4729-9785-27153cbd8f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.8143736642015471\n",
      "Decision Trees Accuracy: 0.7275444005220253\n",
      "Random Forests Accuracy: 0.824279850957992\n",
      "Gradient Boosting Machines Accuracy: 0.8234287227402546\n",
      "XGBoost Accuracy: 0.8257504113786386\n",
      "K-Nearest Neighbors Accuracy: 0.7702284806415616\n"
     ]
    }
   ],
   "source": [
    "# 1. Logistic Regression\n",
    "log_reg = LogisticRegression(max_iter=2500)\n",
    "log_reg.fit(X_train, y_train)\n",
    "log_reg_pred = log_reg.predict(X_test)\n",
    "log_reg_accuracy = accuracy_score(y_test, log_reg_pred)\n",
    "print(\"Logistic Regression Accuracy:\", log_reg_accuracy)\n",
    "\n",
    "# 2. Decision Trees\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train, y_train)\n",
    "dt_pred = dt.predict(X_test)\n",
    "dt_accuracy = accuracy_score(y_test, dt_pred)\n",
    "print(\"Decision Trees Accuracy:\", dt_accuracy)\n",
    "\n",
    "# 3. Random Forests\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "rf_pred = rf.predict(X_test)\n",
    "rf_accuracy = accuracy_score(y_test, rf_pred)\n",
    "print(\"Random Forests Accuracy:\", rf_accuracy)\n",
    "\n",
    "# 4. Gradient Boosting Machines\n",
    "gbm = GradientBoostingClassifier()\n",
    "gbm.fit(X_train, y_train)\n",
    "gbm_pred = gbm.predict(X_test)\n",
    "gbm_accuracy = accuracy_score(y_test, gbm_pred)\n",
    "print(\"Gradient Boosting Machines Accuracy:\", gbm_accuracy)\n",
    "\n",
    "# 5. XGBoost\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "xgb = XGBClassifier(use_label_encoder=False, n_jobs=-1)\n",
    "xgb.fit(X_train, y_train_encoded)\n",
    "xgb_pred = xgb.predict(X_test)\n",
    "xgb_accuracy = accuracy_score(y_test_encoded, xgb_pred)\n",
    "print(\"XGBoost Accuracy:\", xgb_accuracy)\n",
    "\n",
    "# 6. K-Nearest Neighbors (KNN)\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "knn_pred = knn.predict(X_test)\n",
    "knn_accuracy = accuracy_score(y_test, knn_pred)\n",
    "print(\"K-Nearest Neighbors Accuracy:\", knn_accuracy)\n",
    "\n",
    "# # 5. Support Vector Machines\n",
    "# svm = SVC()\n",
    "# svm.fit(X_train, y_train)\n",
    "# svm_pred = svm.predict(X_test)\n",
    "# svm_accuracy = accuracy_score(y_test, svm_pred)\n",
    "# print(\"Support Vector Machines Accuracy:\", svm_accuracy)\n",
    "\n",
    "# # 6. K-Nearest Neighbors\n",
    "# knn = KNeighborsClassifier()\n",
    "# knn.fit(X_train, y_train)\n",
    "# knn_pred = knn.predict(X_test)\n",
    "# knn_accuracy = accuracy_score(y_test, knn_pred)\n",
    "# print(\"K-Nearest Neighbors Accuracy:\", knn_accuracy)\n",
    "\n",
    "# # 7. Naive Bayes\n",
    "# nb = GaussianNB()\n",
    "# nb.fit(X_train, y_train)\n",
    "# nb_pred = nb.predict(X_test)\n",
    "# nb_accuracy = accuracy_score(y_test, nb_pred)\n",
    "# print(\"Naive Bayes Accuracy:\", nb_accuracy)\n",
    "\n",
    "# # 8. Neural Networks\n",
    "# mlp = MLPClassifier()\n",
    "# mlp.fit(X_train, y_train)\n",
    "# mlp_pred = mlp.predict(X_test)\n",
    "# mlp_accuracy = accuracy_score(y_test, mlp_pred)\n",
    "# print(\"Neural Networks Accuracy:\", mlp_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f289f2a-66bf-4b32-9340-e9475bd2b8f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report Logistic Regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.82      0.98      0.89    165012\n",
      "     Class 1       0.76      0.23      0.35     46095\n",
      "     Class 2       0.00      0.00      0.00       198\n",
      "     Class 3       0.00      0.00      0.00       179\n",
      "\n",
      "    accuracy                           0.81    211484\n",
      "   macro avg       0.39      0.30      0.31    211484\n",
      "weighted avg       0.80      0.81      0.77    211484\n",
      "\n",
      "Classification report Decision Trees\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.83      0.81      0.82    165012\n",
      "     Class 1       0.39      0.42      0.41     46095\n",
      "     Class 2       0.01      0.01      0.01       198\n",
      "     Class 3       0.00      0.00      0.00       179\n",
      "\n",
      "    accuracy                           0.73    211484\n",
      "   macro avg       0.31      0.31      0.31    211484\n",
      "weighted avg       0.74      0.73      0.73    211484\n",
      "\n",
      "Classification report Random Forests\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.84      0.96      0.90    165012\n",
      "     Class 1       0.72      0.33      0.45     46095\n",
      "     Class 2       1.00      0.01      0.01       198\n",
      "     Class 3       0.00      0.00      0.00       179\n",
      "\n",
      "    accuracy                           0.82    211484\n",
      "   macro avg       0.64      0.33      0.34    211484\n",
      "weighted avg       0.81      0.82      0.80    211484\n",
      "\n",
      "Classification report Gradient Boosting Machines\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.83      0.97      0.90    165012\n",
      "     Class 1       0.72      0.32      0.44     46095\n",
      "     Class 2       0.00      0.00      0.00       198\n",
      "     Class 3       0.00      0.00      0.00       179\n",
      "\n",
      "    accuracy                           0.82    211484\n",
      "   macro avg       0.39      0.32      0.33    211484\n",
      "weighted avg       0.81      0.82      0.79    211484\n",
      "\n",
      "Classification report XGBoost\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.96      0.90    165012\n",
      "           1       0.72      0.34      0.46     46095\n",
      "           2       0.00      0.00      0.00       198\n",
      "           3       0.00      0.00      0.00       179\n",
      "\n",
      "    accuracy                           0.83    211484\n",
      "   macro avg       0.39      0.33      0.34    211484\n",
      "weighted avg       0.81      0.83      0.80    211484\n",
      "\n",
      "Classification report K-Nearest Neighbors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.80      0.94      0.86    165012\n",
      "     Class 1       0.44      0.17      0.24     46095\n",
      "     Class 2       0.00      0.00      0.00       198\n",
      "     Class 3       0.00      0.00      0.00       179\n",
      "\n",
      "    accuracy                           0.77    211484\n",
      "   macro avg       0.31      0.28      0.28    211484\n",
      "weighted avg       0.72      0.77      0.73    211484\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Classification report Logistic Regression\n",
    "print('Classification report Logistic Regression')\n",
    "print(classification_report(y_test, log_reg_pred))\n",
    "\n",
    "# Classification report Decision Trees\n",
    "print('Classification report Decision Trees')\n",
    "print(classification_report(y_test, dt_pred))\n",
    "\n",
    "# Classification report Random Forests\n",
    "print('Classification report Random Forests')\n",
    "print(classification_report(y_test, rf_pred))\n",
    "\n",
    "# Classification report Gradient Boosting Machines\n",
    "print('Classification report Gradient Boosting Machines')\n",
    "print(classification_report(y_test, gbm_pred))\n",
    "\n",
    "# Classification report XGBoost\n",
    "print('Classification report XGBoost')\n",
    "print(classification_report(y_test_encoded, xgb_pred))\n",
    "\n",
    "# Classification report K-Nearest Neighbors\n",
    "print('Classification report K-Nearest Neighbors')\n",
    "print(classification_report(y_test, knn_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51dfc1ae-63d3-48b8-8b98-7256515f2cf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix Logistic Regression:\n",
      "[[161690   3322      0      0]\n",
      " [ 35558  10537      0      0]\n",
      " [   188     10      0      0]\n",
      " [   124     55      0      0]]\n",
      "Confusion matrix Decision Trees:\n",
      "[[134388  30325    181    118]\n",
      " [ 26430  19474     70    121]\n",
      " [   133     63      2      0]\n",
      " [    89     90      0      0]]\n",
      "Confusion matrix Random Forests:\n",
      "[[159035   5977      0      0]\n",
      " [ 30809  15286      0      0]\n",
      " [   179     18      1      0]\n",
      " [   100     79      0      0]]\n",
      "Confusion matrix Gradient Boosting Machines:\n",
      "[[159531   5477      3      1]\n",
      " [ 31479  14611      4      1]\n",
      " [   181     17      0      0]\n",
      " [   101     78      0      0]]\n",
      "Confusion matrix XGBoost:\n",
      "[[159135   5876      1      0]\n",
      " [ 30596  15498      0      1]\n",
      " [   177     21      0      0]\n",
      " [    96     83      0      0]]\n",
      "Confusion matrix K-Nearest Neighbors:\n",
      "[[155161   9851      0      0]\n",
      " [ 38365   7730      0      0]\n",
      " [   185     13      0      0]\n",
      " [   122     57      0      0]]\n"
     ]
    }
   ],
   "source": [
    "# 1. Logistic Regression\n",
    "print('Confusion matrix Logistic Regression:')\n",
    "print(confusion_matrix(y_test, log_reg_pred))\n",
    "\n",
    "# 2. Decision Trees\n",
    "print('Confusion matrix Decision Trees:')\n",
    "print(confusion_matrix(y_test, dt_pred))\n",
    "\n",
    "# 3. Random Forests\n",
    "print('Confusion matrix Random Forests:')\n",
    "print(confusion_matrix(y_test, rf_pred))\n",
    "\n",
    "# 4. Gradient Boosting Machines\n",
    "print('Confusion matrix Gradient Boosting Machines:')\n",
    "print(confusion_matrix(y_test, gbm_pred))\n",
    "\n",
    "# 5.XGBoost\n",
    "print('Confusion matrix XGBoost:')\n",
    "print(confusion_matrix(y_test_encoded, xgb_pred))\n",
    "\n",
    "# 6.K-Nearest Neighbors\n",
    "print('Confusion matrix K-Nearest Neighbors:')\n",
    "print(confusion_matrix(y_test, knn_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
